{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "install.packages('tm', repos=\"http://cran.us.r-project.org\")\n",
    "install.packages('SnowballC', repos=\"http://cran.us.r-project.org\")\n",
    "install.packages('caTools', repos=\"http://cran.us.r-project.org\")\n",
    "install.packages('e1071', repos=\"http://cran.us.r-project.org\")\n",
    "library(tm)\n",
    "library(SnowballC)\n",
    "library(caTools)\n",
    "library(randomForest)\n",
    "library(e1071)\n",
    "\n",
    "dataset_original = read.delim('Google_Reviewsss.txt', quote= '', stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create The Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = VCorpus(VectorSource(dataset_original$Content))\n",
    "corpus = tm_map(corpus, content_transformer(tolower))\n",
    "corpus = tm_map(corpus, removeNumbers)\n",
    "corpus = tm_map(corpus, removePunctuation)\n",
    "corpus = tm_map(corpus, removeWords, stopwords())\n",
    "corpus = tm_map(corpus, stemDocument)\n",
    "corpus = tm_map(corpus, stripWhitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = DocumentTermMatrix(corpus)\n",
    "dtm = removeSparseTerms(dtm, 0.999)\n",
    "dataset = as.data.frame(as.matrix(dtm))\n",
    "dataset$Thumbs = dataset_original$Thumbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Training & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset$Thumbs = factor(dataset$Thumbs, levels = c(0,1))\n",
    "set.seed(123)\n",
    "split = sample.split(dataset$Thumbs, SplitRatio =.15)\n",
    "training_set = subset(dataset, split == TRUE)\n",
    "test_set = subset(dataset, split == FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement NLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = naiveBayes(x = training_set[-206],\n",
    "                        y = training_set$Thumbs)\n",
    "y_pred = predict(classifier, newdata = test_set[-206])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = table(test_set[, 205], y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
